{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import utils\n",
    "import backward\n",
    "import forward\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCNN(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    ######################################\n",
    "    ############## Forward ###############\n",
    "    ######################################   \n",
    "    \n",
    "    def forwardPass(self, X, y, params):\n",
    "        \n",
    "        k1 ,k2  ,w3  ,w4 ,b1 ,b2 ,b3 ,b4 = params \n",
    "        \n",
    "        z1 = forward.convolve(self, X, k1, b1, stride = 1)\n",
    "        c1 = utils.relu(self, z1)\n",
    "        \n",
    "        p1 = forward.pool(self, c1, filSize = (2,2), stride = 2)\n",
    "        \n",
    "        z2 = forward.convolve(self, p1, k2, b2, stride = 1)\n",
    "        c2 = utils.relu(self, z2)\n",
    "        \n",
    "        p2 = forward.pool(self, c2, filSize = (3,3), stride = 2)\n",
    "        p2Flat = p2.flatten().reshape(1,1600)\n",
    "        \n",
    "        z3 = (w3.dot(p2Flat.T)).reshape(64,1)+b3\n",
    "        f1 = utils.relu(self, z3)\n",
    "\n",
    "        z4 = w4.dot(z3).reshape(10,1)+b4\n",
    "        f2 = utils.softmax(self,z4)  \n",
    "        \n",
    "        cost = forward.loss(self, f2, y)\n",
    "        \n",
    "        fp = [z1,c1,p1,z2,c2,p2,p2Flat,z3,f1,z4,f2]\n",
    "        \n",
    "        return (cost, fp)\n",
    "    \n",
    "     ######################################\n",
    "     ############# Backward ###############\n",
    "     ######################################\n",
    "    \n",
    "    def backwardPass(self, params, cost, fp, X, y):\n",
    "        z1,c1,p1,z2,c2,p2,p2Flat,z3,f1,z4,f2 = fp\n",
    "        k1 ,k2  ,w3  ,w4 ,b1 ,b2 ,b3 ,b4 = params\n",
    "        \n",
    "        grads = []\n",
    "        \n",
    "        # fc second gradient\n",
    "        df2, dw4, db4 = backward.fc_grad_second(self, y, f2, f1)\n",
    "\n",
    "        # fc first gradient\n",
    "        df1, dw3, db3 = backward.fc_grad_first(self, df2, dw4, p2Flat, z1)\n",
    "\n",
    "        # flattened pool 2 gradient\n",
    "        dp2Flat = dw3.T.dot(df1)\n",
    "        dp2 = np.reshape(dp2Flat, p2.shape)\n",
    "\n",
    "        # conv 2 gradient\n",
    "        dc2 = backward.maxpool_gradient(self, c2, dp2, filSize = (3, 3), stride = 2)\n",
    "        dc2[c2<=0] = 0\n",
    "\n",
    "        # pool 1 gradient\n",
    "        dp1, dk2, db2 = backward.convolution_gradient(self, dc2, p1, k2, b2, filSize = (3,3), stride = 1)\n",
    "\n",
    "        # conv 1 gradient\n",
    "        dc1 = backward.maxpool_gradient(self, c1, dp1, filSize = (2, 2), stride = 2)\n",
    "        dc1[c1<=0] = 0\n",
    "\n",
    "        # image gradient \n",
    "        dX, dk1, db1 = backward.convolution_gradient(self, dc1, X, k1, b1, filSize = (3,3), stride = 1)\n",
    "        \n",
    "        grads = [df2, dw4, db4,df1, dw3, db3,dp2,dc2,dp1, dk2, db2,dc1,dX, dk1, db1]\n",
    "        return grads\n",
    "\n",
    "    ######################################\n",
    "    ########### Optimization #############\n",
    "    ######################################\n",
    "\n",
    "    def optimize(self, alpha, beta1, beta2, epsilon, moments, grads, params, t, batchSize):\n",
    "        \"\"\"\n",
    "        1 - Initialize a step size, alpha\n",
    "        2 - Initialize exponential decay rates for first and second order moment estimates of the gradients, \n",
    "            beta1 & beta2\n",
    "        3 - Obtain the stochastic functions (the loss) from the forward pass\n",
    "        4 - Obtain parameters (kn, wn, bn) from the forward pass\n",
    "        5 - Initialize first order moment, mo\n",
    "        6 - Initialize second order moment, vo\n",
    "        7 - Initialize timestep\n",
    "        \"\"\"\n",
    "        v1,m1,bv1,bm1,v2,m2,bv2,bm2,v3,m3,bv3,bm3,v4,m4,bv4,bm4 = moments\n",
    "        df2, dw4, db4,df1, dw3, db3,dp2,dc2,dp1, dk2, db2,dc1,dX, dk1, db1 = grads\n",
    "        k1,k2  ,w3  ,w4 ,b1 ,b2 ,b3 ,b4 = params\n",
    "                \n",
    "        # Get first and second moment estimates\n",
    "        m1 = beta1 * m1 + (1-beta1) * dk1/batchSize\n",
    "        v1 = beta2 * v1 + (1-beta2) * (dk1/batchSize)**2\n",
    "        bm1 = beta1 * bm1 + (1-beta1) * db1/batchSize\n",
    "        bv1 = beta2 * bv1 + (1-beta2) * (db1/batchSize)**2\n",
    "\n",
    "        m2 = beta1 * m2 + (1-beta1) * dk2/batchSize\n",
    "        v2 = beta2 * v2 + (1-beta2) * (dk2/batchSize)**2\n",
    "        bm2 = beta1 * bm2 + (1-beta1) * db2/batchSize\n",
    "        bv2 = beta2 * bv2 + (1-beta2) * (db2/batchSize)**2\n",
    "\n",
    "        m3 = beta1 * m3 + (1-beta1) * dw3/batchSize\n",
    "        v3 = beta2 * v3 + (1-beta2) * (dw3/batchSize)**2\n",
    "        bm3 = beta1 * bm3 + (1-beta1) * db3/batchSize\n",
    "        bv3 = beta2 * bv3 + (1-beta2) * (db3/batchSize)**2\n",
    "\n",
    "        m4 = beta1 * m4 + (1-beta1) * dw4/batchSize\n",
    "        v4 = beta2 * v4 + (1-beta2) * (dw4/batchSize)**2\n",
    "        bm4 = beta1 * bm4 + (1-beta1) * db4/batchSize\n",
    "        bv4 = beta2 * bv4 + (1-beta2) * (db4/batchSize)**2\n",
    "\n",
    "        # Correct estimates for zero bias\n",
    "        \n",
    "        v1 = v1 / (1-beta2**t)\n",
    "        bm1 = bm1 / (1-beta1**t)\n",
    "        bv1 = bv1 / (1-beta2**t)\n",
    "\n",
    "        m2 = m2 / (1-beta1**t)\n",
    "        v2 = v2 / (1-beta2**t)\n",
    "        bm2 = bm2 / (1-beta1**t)\n",
    "        bv2 = bv2 / (1-beta2**t)\n",
    "\n",
    "        m3 = m3 / (1-beta1**t)\n",
    "        v3 = v3 / (1-beta2**t)\n",
    "        bm3 = bm3 / (1-beta1**t)\n",
    "        bv3 = bv3 / (1-beta2**t)\n",
    "\n",
    "        m4 = m4 / (1-beta1**t)\n",
    "        v4 = v4 / (1-beta2**t)\n",
    "        bm4 = bm4 / (1-beta1**t)\n",
    "        bv4 = bv4 / (1-beta2**t)\n",
    "\n",
    "        # Update parameters\n",
    "        k1 -= alpha*m1/(np.sqrt(v1 + epsilon))\n",
    "        b1 -= alpha*bm1/(np.sqrt(bv1 + epsilon))\n",
    "\n",
    "        k2 -= alpha*m2/(np.sqrt(v2 + epsilon))\n",
    "        b2 -= alpha*bm2/(np.sqrt(bv2 + epsilon))\n",
    "\n",
    "        w3 -= alpha*m3/(np.sqrt(v3 + epsilon))\n",
    "        b3 -= alpha*bm3/(np.sqrt(bv3 + epsilon))\n",
    "\n",
    "        w4 -= alpha*m4/(np.sqrt(v4 + epsilon))\n",
    "        b4 -= alpha*bm4/(np.sqrt(bv4 + epsilon))\n",
    "        \n",
    "        # return updated parameters\n",
    "        newParams = [k1,k2,w3,w4,b1,b2,b3,b4]\n",
    "        \n",
    "        return newParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now optimizing: epoch  1\n",
      "average cost:  2.4020782075067157\n",
      "now optimizing: epoch  2\n",
      "average cost:  2.377868983514366\n",
      "now optimizing: epoch  3\n",
      "average cost:  2.373417179883282\n",
      "now optimizing: epoch  4\n",
      "average cost:  2.374710771120108\n",
      "now optimizing: epoch  5\n",
      "average cost:  2.3690391516507026\n",
      "now optimizing: epoch  6\n",
      "average cost:  2.3562317444532437\n",
      "now optimizing: epoch  7\n",
      "average cost:  2.3562317444532437\n",
      "now optimizing: epoch  8\n",
      "average cost:  2.3562317444532437\n",
      "now optimizing: epoch  9\n",
      "average cost:  2.3562317444532437\n",
      "now optimizing: epoch  10\n",
      "average cost:  2.3562317444532437\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "This whole cell will later go into a class or function\n",
    "\"\"\"\n",
    "\n",
    "########################################## Initialization step ##########################################\n",
    "\n",
    "# load the data\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
    "train_images = train_images.reshape((1, 28, 28, 60000)) # (channels, rows, cols, imgs)\n",
    "test_images = test_images.reshape((1, 28, 28, 10000)) # (channels, rows, cols, imgs)\n",
    "\n",
    "# normalization of the image pixel values\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# break up data, first 10 images \n",
    "batchSize = 10\n",
    "train_image = train_images[:,:,:,0:batchSize].reshape(1,28,28,batchSize) # batchsize x 28 pixels x 28 pixels x 1\n",
    "train_label = train_labels[0:batchSize].reshape(batchSize)\n",
    "\n",
    "\n",
    "# initialize parameters (2 convolution, 2 pool, 2 fully connected)\n",
    "\"\"\"\n",
    "kn = conv. kernels\n",
    "wn = fc. weights\n",
    "\"\"\"\n",
    "\n",
    "k1 = np.random.randn(32, 1, 3, 3)\n",
    "k2 = np.random.randn(64, 32, 3, 3)\n",
    "w3 = np.random.randn(64, 1600) * 0.01\n",
    "w4 = np.random.randn(10, 64) * 0.01\n",
    "\n",
    "b1 = np.zeros((k1.shape[0],1))\n",
    "b2 = np.zeros((k2.shape[0],1))\n",
    "b3 = np.zeros((w3.shape[0],1))\n",
    "b4 = np.zeros((w4.shape[0],1))\n",
    "\n",
    "# Initialize optimization moments\n",
    "v1 = np.zeros(k1.shape)\n",
    "m1 = np.zeros(k1.shape)\n",
    "bv1 = np.zeros(b1.shape)\n",
    "bm1 = np.zeros(b1.shape)\n",
    "\n",
    "v2 = np.zeros(k2.shape)\n",
    "m2 = np.zeros(k2.shape)\n",
    "bv2 = np.zeros(b2.shape)\n",
    "bm2 = np.zeros(b2.shape)\n",
    "\n",
    "v3 = np.zeros(w3.shape)\n",
    "m3 = np.zeros(w3.shape)\n",
    "bv3 = np.zeros(b3.shape)\n",
    "bm3 = np.zeros(b3.shape)\n",
    "\n",
    "v4 = np.zeros(w4.shape)\n",
    "m4 = np.zeros(w4.shape)\n",
    "bv4 = np.zeros(b4.shape)\n",
    "bm4 = np.zeros(b4.shape)\n",
    "\n",
    "params = [k1, k2, w3, w4, b1, b2, b3, b4]\n",
    "moments = [v1,m1,bv1,bm1,v2,m2,bv2,bm2,v3,m3,bv3,bm3,v4,m4,bv4,bm4]\n",
    "\n",
    "########################################## Training step #########################################\n",
    "\n",
    "\"\"\"\n",
    "To train, specify number of epochs. Batch size was determined earlier to break up the data. This method isn't permanent.\n",
    "\"\"\"\n",
    "\n",
    "Y = np.zeros((batchSize,numLabels,1))\n",
    "numEpochs = 10\n",
    "numLabels = 10 \n",
    "\n",
    "# for each image in batch, one iteration = forward, backward, and optimization\n",
    "for epoch in range(numEpochs):\n",
    "    cost = []\n",
    "    for img in range(batchSize):\n",
    "        Y[img,train_label[img]] = 1.                                         # one hot vector labels\n",
    "        image, label = train_image[:,:,:,img],Y[img]\n",
    "        loss, fp = myCNN().forwardPass(image, label, params)                     # this returns the loss and forward pass\n",
    "        grads =  myCNN().backwardPass(params, loss, fp, image, label)            # this returns the gradiets w.r.t the loss\n",
    "        cost.append(loss)\n",
    "        if (img+1) % batchSize == 0:\n",
    "            print(\"now optimizing: epoch \", epoch+1)\n",
    "            params = myCNN().optimize(0.001, 0.9, 0.999, 1E-7, moments, grads, params, img, batchSize)\n",
    "            print(\"average cost: \", sum(cost)/batchSize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
